<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Shader Audio</title>
    <script id="shader-vs" type="x-shader/x-vertex">#version 300 es
        in vec4 position;void main(void){gl_Position = position;}
    </script>
    <script id="shader-fs" type="x-shader/x-fragment" src="./sound.frag.glsl">#version 300 es
        #define M_PI2 6.28318530717958647692528676755900576839
        precision highp float;
        out vec4 fragColor;
        //out float fragColor;
        uniform float u_curr_buffer;
        uniform float u_sample_rate; // USUALLY 44100
        uniform float u_buffer_size;

        float channels = 1.;
        float time = 0.;
        float currSample = 0.;
        float bar = 0.;
        float beat = 0.;
        float bpm = 300.;
        float secondsPerSample = 0.;
        float secondsPerBeat = 0.;
        float secondsPerBar = 0.;
        float samplesPerBeat = 0.;
        float samplesPerBar = 0.;


        struct Note {
            int note;
            float vel;
            float startSample;
            float atk;
            float rel;
        };

        struct SampleInfo {
            float curr;
            float time;
            float bar;
            float beat;
        };

        SampleInfo getInfoForSampleN(float n) {
            float bar = floor(n / samplesPerBar);
            SampleInfo info = SampleInfo(
                n,
                n/u_sample_rate,
                bar,
                floor((n - bar * samplesPerBar) / samplesPerBeat)
            );
            return info;
        }

        float getFreq(int note) {
            float mA_F = 220.0;
            int mA_N = 57;
            return pow(2.0, float(note - mA_N) / 12.0) * mA_F;
        }

        Note getNoteFor(float bar, float beat) {
            if (beat < 0. ) {
                beat = 4.;
                bar -= 1.;
            }

            int arp[16] = int[](7,-12,0,-12,0,-12,7,-12,0,-12,0,-12,10,-12,0,-12);
            float arpInt[16] = float[](1.,.5,1.,.5,1.,.5,1.,.5,1.,.5,1.,.5,1.,.5,1.,.5);
            int seq[8] = int[](0,0,3,3,-1,3,-4,-2);

            int arpPos = int(beat + mod(bar, 4.) * 4.);
            int seqPos = int(mod(floor(bar / 4.), 8.));

            Note note = Note(
                arp[arpPos] + seq[seqPos] + 58,
                arpInt[arpPos],
                bar * samplesPerBar + beat * samplesPerBeat,
                0.001,
                .5
            );
            return note;
        }

        float getAREnv(float curr, float atk, float rel) {
            float delta = curr - atk;
            float amp = delta < 0. ? curr / atk : delta < rel ? 1. - delta / rel : 0.;
            return amp;
        }

        float renderNote(float atSample, Note n) {
            float noteSecondsOffset = (atSample - n.startSample) * secondsPerSample;
            float freq = getFreq(n.note);
            vec3 sines = vec3(
                sin(noteSecondsOffset * freq * M_PI2) * .5,
                sin(noteSecondsOffset * (freq * 0.505) * M_PI2) * .25,
                sin(noteSecondsOffset * (freq * 1.995) * M_PI2) * .15
            ) ;

            return (sines.r + sines.g + sines.b) * .5
                * n.vel
                * getAREnv(noteSecondsOffset, n.atk, n.rel)
                * .2;
        }

        float render(float sampleN) {

            SampleInfo info = getInfoForSampleN(sampleN);

            Note noteNow = getNoteFor(info.bar, info.beat);
            float res = renderNote(info.curr, noteNow);
            if (info.bar > 0. || info.beat > 0.) {
                Note notePrev = getNoteFor(info.bar, info.beat - 1.);
                res += renderNote(info.curr, notePrev);
            }

            return res;
        }

        void setupGlobals() {
            secondsPerSample = 1. / u_sample_rate;
            secondsPerBeat = 60. / bpm;
            secondsPerBar = secondsPerBeat * 4.;
            samplesPerBeat = u_sample_rate * secondsPerBeat;
            samplesPerBar = samplesPerBeat * 4.;
        }

        void main() {
            setupGlobals();
            float st = (gl_FragCoord.x + gl_FragCoord.y * 512.) * channels
                + u_curr_buffer * u_buffer_size;
                if (channels == 1.) {
                    fragColor = vec4(render(st), 0., 0., 0.);
                } else {
                    fragColor = vec4(render(st), render(st+1.), render(st+2.), render(st+3.));
            }
        }
    </script>
    <script type="text/javascript">
        let started = false;
        const canvas = new OffscreenCanvas(512, 512);
        const bufferinSecs = .2;
        const gl = canvas.getContext('webgl2');
        const channels = 1;
        if (!gl) {
            console.error("Unable to initialize WebGL 2. Your browser may not support it.");
        }
        gl.getExtension('EXT_color_buffer_float');

        function audioSetup() {
            const ctx = new AudioContext();
            const sampleRate = ctx.sampleRate; // often 44100 Hz
            const bufferSize = sampleRate * bufferinSecs; // total number of samples = sampleRate * duration
            document.getElementById("sampleRateUx").innerText = sampleRate;

            return {
                ctx,
                sampleRate, // often 44100 Hz
                buffer: {
                    size: bufferSize, // total number of samples = sampleRate * duration
                    obj: {
                        w: 512,
                        h: Math.ceil((bufferSize) / 512 * channels)
                    },
                    data: ctx.createBuffer(2, bufferSize * 2, sampleRate)
                }
            }
        }

        function addInlineShader(id) {
            const script = document.getElementById(id);
            const type = script.type === "x-shader/x-fragment" ? gl.FRAGMENT_SHADER : gl.VERTEX_SHADER;
            const shader = gl.createShader(type);
            gl.shaderSource(shader, script.text);
            gl.compileShader(shader);
            if (!gl.getShaderParameter(shader, gl.COMPILE_STATUS)) {
                console.error(gl.getShaderInfoLog(shader));
                return false;
            }
            return shader;
        }

        document.addEventListener("click", function () {
            if (!started) {
                started = true;
                init();
            }
        });

        function init () {
            const audio = audioSetup();
            const program = gl.createProgram();
            gl.attachShader(program, addInlineShader("shader-vs"));
            gl.attachShader(program, addInlineShader("shader-fs"));
            gl.linkProgram(program);
            if (!gl.getProgramParameter(program, gl.LINK_STATUS)) {
                console.error(gl.getProgramInfoLog(program));
                return;
            }
            gl.useProgram(program);

            // UNIFORMS
            var bufferIndexLoc = gl.getUniformLocation(program, "u_curr_buffer");
            gl.uniform1f(bufferIndexLoc, 0.);
            var bufferLengthLoc = gl.getUniformLocation(program, "u_buffer_size");
            gl.uniform1f(bufferLengthLoc, audio.buffer.size);
            var sampleRateLoc = gl.getUniformLocation(program, "u_sample_rate");
            gl.uniform1f(sampleRateLoc, audio.sampleRate);


            /// INIT THE VERTICES FOR THE TRIANGLE STRIP
            const v = 1.0;
            let vertices = new Float32Array([-v, v, -v, -v, v, v, v, -v]);
            let vertexBuffer = gl.createBuffer();
            gl.bindBuffer(gl.ARRAY_BUFFER, vertexBuffer);
            gl.bufferData(gl.ARRAY_BUFFER, vertices, gl.STATIC_DRAW);
            let position = gl.getAttribLocation(program, 'position');
            gl.vertexAttribPointer(position, 2, gl.FLOAT, false, 0, 0);
            gl.enableVertexAttribArray(position);

            // INITIALIZES THE CONTEXT FRAMEBUFFER
            let framebuffer = gl.createFramebuffer();
            gl.bindFramebuffer(gl.FRAMEBUFFER, framebuffer);

            // INITIALIZES THE TEXTURE
            let texture = gl.createTexture();
            gl.bindTexture(gl.TEXTURE_2D, texture);
            //gl.texImage2D(gl.TEXTURE_2D, 0, gl.RGBA32F, audio.buffer.obj.w, audio.buffer.obj.h, 0, gl.RGBA, gl.FLOAT, null); // <- 4 channels
            gl.texImage2D(gl.TEXTURE_2D, 0, gl.R32F, audio.buffer.obj.w, audio.buffer.obj.h, 0, gl.RED, gl.FLOAT, null);

            try {
                gl.framebufferTexture2D(gl.FRAMEBUFFER, gl.COLOR_ATTACHMENT0, gl.TEXTURE_2D, texture, 0);
            } catch(e) {
                console.error(e);
                return;
            }
            // Check framebuffer status if needed
            const fbStatus = gl.checkFramebufferStatus(gl.FRAMEBUFFER);
            if (fbStatus === 0) {
                console.error("Error on framebuffer");
                return;
            }
            if (fbStatus !== gl.FRAMEBUFFER_COMPLETE) {
                console.error("Error setting up framebuffer::" + fbStatus);
                return;
            }

            let time = Date.now();
            let rendered = 0;
            let curr_buffer_index = 0.0;
            let where = true;
            let audioData = new Float32Array(audio.buffer.obj.w * audio.buffer.obj.h * channels);
            debugger;
            const bufferInMillis = bufferinSecs * 1000.;
            function render() {
                const now = Date.now();
                if (rendered === 2) {
                    let sizedAudioData = audioData.subarray(0, audio.buffer.size);
                    audio.buffer.data.copyToChannel(sizedAudioData, 0, !where ? 0 : audio.buffer.size); // Left Channel
                    audio.buffer.data.copyToChannel(sizedAudioData, 1, !where ? 0 : audio.buffer.size); // Right Channel
                    where = !where;
                }
                if (rendered === 0) {
                    /// NOW!!! get DA DATA!!!
                    gl.uniform1f(bufferIndexLoc, curr_buffer_index);
                    gl.drawArrays(gl.TRIANGLE_STRIP, 0, vertices.length * .5);
                    // GRAB IT!!
                    //gl.readPixels(0, 0, audio.buffer.obj.w, audio.buffer.obj.h, gl.RGBA, gl.FLOAT, audioData);  // <- 4 channels
                    gl.readPixels(0, 0, audio.buffer.obj.w, audio.buffer.obj.h, gl.RED, gl.FLOAT, audioData);
                }
                rendered ++;
                if (now - time >= bufferInMillis) {
                    curr_buffer_index += 1.0;
                    time += bufferInMillis;
                    rendered = 0;
                }
                window.requestAnimationFrame(render);
            }
            window.requestAnimationFrame(render);

            let bufferSource = false;
            function resumeBufferSource(bs) {
                if (!bs) {
                    bs = audio.ctx.createBufferSource();
                    bs.buffer = audio.buffer.data;
                    bs.connect(audio.ctx.destination);
                    bs.start();
                    bs.loop = true;
                }
            }
            function pauseBufferSource(bs) {
                if (bs) {
                    bs.stop();
                }
                //bs = false;
            }
            resumeBufferSource(bufferSource);

            window.addEventListener("focus", () => {resumeBufferSource(bufferSource);});
            window.addEventListener("blur", () => {pauseBufferSource(bufferSource);});
        };
    </script>
</head>
<body>
    <p>v: 0.0.001</p>
    <ul>
        <li style="display:flex;align-items: center;"><label>SampleRate:</label><p id="sampleRateUx"></p></li>
    </ul>
</body>
</html>